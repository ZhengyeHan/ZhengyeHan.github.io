---
title: "NeurIPS 2024 Competition Track: Auto-Bidding in Large-Scale Auctions: Learning Decision-Making in Uncertain and Competitive Games"
excerpt: "This competition was hosted by the PKU-Alimama Artificial Intelligence Innovation Joint Lab, a collaboration between Alibaba Group 
and Peking University. As a member of the lab, I was actively involved in organizing the competition. I worked closely with Shuai Dou and Yeshu Li to develop the agents 
for the competition system, focusing on creating robust models for decision-making in large-scale, competitive auctions."
collection: portfolio
---

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research and Development in Reinforcement Learning at Alibaba Group</title>
</head>
<body>
    <h2>Background</h2>
    <p>
        This project was conducted during my internship at <strong>Alibaba Group</strong>, a globally renowned top 100 company. This internship offered me invaluable exposure to real-world machine learning applications.
        <h1>BCB Budget Constrained Bidding Model</h1>
    
        <h2>问题描述</h2>
        <p>目标是设计一个出价策略 <b>b<sub>t</sub></b>（出价值），在满足预算限制的同时最大化广告效果，如点击次数（CTR）或转化次数（CVR）。</p>
    
        <h2>公式化</h2>
    
        <h3>决策变量</h3>
        <p><span class="formula"><b>b<sub>t</sub></b></span>：时间 <i>t</i> 时的出价值。</p>
    
        <h3>输入参数</h3>
        <ul>
            <li><b>T</b>：总竞价轮数。</li>
            <li><b>B</b>：总预算。</li>
            <li><b>v<sub>t</sub></b>：点击的收益（每轮）。</li>
            <li><b>p<sub>t</sub></b>：点击率。</li>
            <li><b>c<sub>t</sub>(b<sub>t</sub>)</b>：出价 <b>b<sub>t</sub></b> 对应的成本。</li>
        </ul>
    
        <h3>优化目标</h3>
        <p>最大化期望收益：</p>
        <p class="formula">
            max<sub>{b<sub>1</sub>, b<sub>2</sub>, ..., b<sub>T</sub>}</sub> E[∑<sub>t=1</sub><sup>T</sup> p<sub>t</sub> ⋅ v<sub>t</sub>]
        </p>
    
        <h3>预算约束</h3>
        <p class="formula">
            ∑<sub>t=1</sub><sup>T</sup> c<sub>t</sub>(b<sub>t</sub>) ≤ B
        </p>
    </p>

    <h2>Project Overview</h2>
    <p>
        My internship was divided into two major components: 
    </p>
    <ol>
        <li>
            <strong>Developing a new Reinforcement Learning Algorithm:</strong>
            Creating a novel reinforcement learning algorithm.
        </li>
        <li>
            <strong>Organizing the NIPS Competition:</strong>
            Co-organizing the “Auto-Bidding in Large-Scale Auctions” competition at NIPS, including developing Official agents for competitive auction environment(<a href="https://h5case6.xiaoxxx.cn/202406/NeurlIPS/dist/index.html#/?lang=en_us" target="_blank" rel="noopener noreferrer">official website</a>).
        </li>
    </ol>

    <h2>Methodology</h2>
    <h3>1. Reinforcement Learning</h3>
    <p>
        I will disclose the details of my research after the double-blind review.
    </p>

    <h3>2. Organizing the NIPS Competition</h3>
    <p>
        As part of the organizing team for the NIPS competition, I developed reinforcement learning agents capable of participating in large-scale, competitive, real-time auction environments. The system required designing agents with robust auto-bidding capabilities under high uncertainty. My contributions included:
    </p>
    <ul>
        <li>
            Training agents using advanced offline reinforcement learning techniques, including BCQ, CQL, and IQL.
        </li>
        <li>
            Incorporating Google DeepMind's Q-value optimization tricks for industrial applications to improve agent stability and performance.
        </li>
        <li>
            Developing one-third of the official competition agents, with my BCQ agent achieving third place among all baseline agents in the testing phase.
        </li>
    </ul>

    <h2>Key Achievements</h2>
    <ol>
        <li>
            <strong>Practical Impact:</strong>
            Contributed to the NIPS competition as a key organizer and developer, creating robust and competitive baseline agents for participants to challenge.
        </li>
    </ol>

    <h2>Challenges and Reflections</h2>
    <p>
        This internship presented numerous challenges that significantly advanced my skills and understanding of reinforcement learning:
    </p>
    <ol>
        <li>
            <strong>Algorithm Design Complexity:</strong>
            Developing a completely new reinforcement learning algorithm required extensive experimentation and iteration. Over a half-year period, I dedicated myself to continuous experimentation, even setting up a tent near my workstation to ensure uninterrupted model training.
        </li>
        <li>
            <strong>Competency in Safe Reinforcement Learning:</strong>
            Designing agents for a competitive and highly uncertain environment required learning and applying safety constraints in reinforcement learning. These efforts ensured agent stability and effectiveness during competition.
        </li>
    </ol>

    <h2>Conclusion</h2>
    <p>
        This internship profoundly shaped my research direction, enhancing my expertise in reinforcement learning and its industrial applications. My contributions to the NIPS competition solidified my ability to tackle complex challenges and innovate within the field. This experience not only prepared me for further academic pursuits but also underscored the transformative potential of reinforcement learning in solving real-world problems.
    </p>
</body>
</html>
