---
title: "NeurIPS 2024 Competition Track: Auto-Bidding in Large-Scale Auctions: Learning Decision-Making in Uncertain and Competitive Games"
excerpt: "This competition was hosted by the PKU-Alimama Artificial Intelligence Innovation Joint Lab, a collaboration between Alibaba Group 
and Peking University. As a member of the lab, I was actively involved in organizing the competition. I worked closely with Shuai Dou and Yeshu Li to develop the agents 
for the competition system, focusing on creating robust models for decision-making in large-scale, competitive auctions."
collection: portfolio
---

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research and Development in Reinforcement Learning at Alibaba Group</title>
</head>
<body>
    <h2>Background</h2>
    <p>
        This project was conducted during my internship at <strong>Alibaba Group</strong>, a globally renowned top 100 company. This internship offered me invaluable exposure to real-world machine learning applications.
    </p>
    
    <img src="/images/project1.png" alt="Project Overview" style="display: block; margin: 15px auto; max-width: 50%; height: auto;"
    
    <p>BCB Budget Constrained Bidding Model</p>

    <p>problem description</p>
    <p>The goal is to design a bidding strategy <b>b<sub>t</sub></b> (bid value) that maximizes auction revenue while satisfying budget constraints。</p>

    <p>formulation</p>

    <p>decision variable</p>
    <p><span class="formula"><b>b<sub>t</sub></b></span>：time <i>t</i> bid.</p>

    <p>input parameter</p>
    <ul>
        <li><b>T</b>：Total number of bidding rounds.</li>
        <li><b>B</b>：Total budget.</li>
        <li><b>v<sub>t</sub></b>：Revenue from winning the auction.</li>
        <li><b>c<sub>t</sub>(b<sub>t</sub>)</b>：The cost corresponding to bidding <b>b<sub>t</sub></b>.</li>
    </ul>

    <p>optimization objective</p>
    <p>Maximizing expected revenue:</p>
    <p class="formula">
        max<sub>{b<sub>1</sub>, b<sub>2</sub>, ..., b<sub>T</sub>}</sub> E[∑<sub>t=1</sub><sup>T</sup> p<sub>t</sub> ⋅ v<sub>t</sub>]
    </p>

    <p>budget constraint</p>
    <p class="formula">
        ∑<sub>t=1</sub><sup>T</sup> c<sub>t</sub>(b<sub>t</sub>) ≤ B
    </p>

    <h2>Project Overview</h2>
    <p>
        My internship was divided into two major components: 
    </p>
    <ol>
        <li>
            <strong>Developing a new Reinforcement Learning Algorithm:</strong>
            Creating a novel reinforcement learning algorithm.
        </li>
        <li>
            <strong>Organizing the NIPS Competition:</strong>
            Co-organizing the “Auto-Bidding in Large-Scale Auctions” competition at NIPS, including developing Official agents for competitive auction environment(<a href="https://h5case6.xiaoxxx.cn/202406/NeurlIPS/dist/index.html#/?lang=en_us" target="_blank" rel="noopener noreferrer">official website</a>).
        </li>
    </ol>

    <h2>Methodology</h2>
    <h3>1. Reinforcement Learning</h3>
    <p>
        I will disclose the details of my research after the double-blind review.
    </p>

    <h3>2. Organizing the NIPS Competition</h3>
    <p>
        As part of the organizing team for the NIPS competition, I developed reinforcement learning agents capable of participating in large-scale, competitive, real-time auction environments. The system required designing agents with robust auto-bidding capabilities under high uncertainty. My contributions included:
    </p>
    <ul>
        <li>
            Training agents using advanced offline reinforcement learning techniques, including BCQ, CQL, and IQL.
        </li>
        <li>
            Incorporating Google DeepMind's Q-value optimization tricks for industrial applications to improve agent stability and performance.
        </li>
        <li>
            Developing one-third of the official competition agents, with my BCQ agent achieving third place among all baseline agents in the testing phase.
        </li>
    </ul>

    <h2>Key Achievements</h2>
    <ol>
        <li>
            <strong>Practical Impact:</strong>
            Contributed to the NIPS competition as a key organizer and developer, creating robust and competitive baseline agents for participants to challenge.
        </li>
    </ol>

    <h2>Challenges and Reflections</h2>
    <p>
        This internship presented numerous challenges that significantly advanced my skills and understanding of reinforcement learning:
    </p>
    <ol>
        <li>
            <strong>Algorithm Design Complexity:</strong>
            Developing a completely new reinforcement learning algorithm required extensive experimentation and iteration. Over a half-year period, I dedicated myself to continuous experimentation, even setting up a tent near my workstation to ensure uninterrupted model training.
        </li>
        <li>
            <strong>Competency in Safe Reinforcement Learning:</strong>
            Designing agents for a competitive and highly uncertain environment required learning and applying safety constraints in reinforcement learning. These efforts ensured agent stability and effectiveness during competition.
        </li>
    </ol>

    <h2>Conclusion</h2>
    <p>
        This internship profoundly shaped my research direction, enhancing my expertise in reinforcement learning and its industrial applications. My contributions to the NIPS competition solidified my ability to tackle complex challenges and innovate within the field. This experience not only prepared me for further academic pursuits but also underscored the transformative potential of reinforcement learning in solving real-world problems.
    </p>
</body>
</html>
