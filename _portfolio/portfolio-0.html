---
title: "Large Language Models in Iterated Prisoner's Dilemma: Impact of High-level behavior prompter on Cooperation"
excerpt: "This project, conducted under the supervision of Professor Zhigang Cao, explores the intersection of LLMs and game theory, it formed my undergraduate thesis. I analyzed the behavior of LLMs in the Iterated Prisoner's Dilemma and developed a high-level cueing algorithm to increase their cooperation rates in this game theory scenario."
collection: portfolio
---

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Behavior Research of LLMs in Iterated Prisoner’s Dilemma</title>
</head>
<body>
    <h2>Background</h2>
    <p>
        This project explores the intersection of <strong>AI and game theory</strong>. 
        Motivated by the growing prominence of large language models (LLMs) and their potential applications, The primary objective of this project is to investigate the behavioral performance of LLMs in the classical game-theoretic scenario of the Iterated Prisoner’s Dilemma (IPD). Additionally, it aims to enhance the cooperation rate among agents in this game through a high-level behavioral prompting mechanism, trained using a Transformer model.
        By fostering higher levels of collaboration, this approach ultimately increases the overall societal payoff and offers a novel perspective on multi-agent cooperation.. 
        This research received a nomination for Outstanding Undergraduate Graduation Project.
    </p>

    <img src="/images/bs.png" alt="Project Overview" style="display: block; margin: 15px auto; max-width: 70%; height: auto;">

    <p>
    Repeated Prisoner’s Dilemma (IPD) is a classical model in game theory and is widely applied in fields such as evolutionary biology, economics, and computer science. In IPD, participants choose between cooperation and defection in each round of the game, with their decisions directly affecting their immediate and long-term rewards. The core of IPD lies in its ability to reveal the dynamic relationship between cooperation and betrayal, especially in environments with repeated interactions.
    </p>

    <p>
    The payoff structure of IPD, as shown below, reflects the outcomes of different strategies:
    </p>
    
    <img src="/images/prisoner_dilemma.png" alt="Project Overview" style="display: block; margin: 15px auto; max-width: 70%; height: auto;"
    <ul>
        <li><strong>Mutual Cooperation:</strong> Both players receive a payoff of 3 points.</li>
        <li><strong>Unilateral Defection:</strong> The defector earns 5 points, while the cooperator earns 0 points.</li>
        <li><strong>Mutual Defection:</strong> Both players receive a payoff of 1 point.</li>
    </ul>
    

    <h2>Objectives</h2>
    <ol>
        <li><strong>LLM Behavior Analysis:</strong> To examine the intrinsic behavioral tendencies of LLMs in game-theoretic scenarios, specifically cooperation and betrayal in RPD.</li>
        <li><strong>Enhancing Cooperation:</strong> To design a high-level behavioral prompting mechanism that leverages historical game data to guide LLMs towards higher cooperative rates in iterative dilemmas.</li>
    </ol>
    
    <h2>Methodology</h2>
    <img src="/images/prisoner_dilemma_mathod.png" alt="Project Overview" style="display: block; margin: 15px auto; max-width: 70%; height: auto;"
    <p>The project involved designing a custom experimental environment to simulate repeated Prisoner’s Dilemma interactions among multiple LLMs, such as ChatGPT and Tongyi Qianwen. The primary steps included:</p>
    <ul>
        <li><strong>Game Environment Setup:</strong> Developing a simulation framework for repeated RPD experiments and integrating API-based interactions with various LLMs.</li>
        <li><strong>Behavioral Prompting Mechanism:</strong> Drawing inspiration from the hierarchy decision transformer model, a high-level transformer was developed to process historical game data and generate strategic prompts for LLMs. This mechanism aimed to enhance cooperative outcomes during their interactions.</li>
        <li><strong>Empirical Evaluation:</strong> Analyzing LLM behavior with and without the high-level prompting mechanism to quantify its impact on cooperative behavior.</li>
    </ul>
    
    <h2>Key Achievements</h2>
    <img src="/images/prisoner_dilemma_result.png" alt="Project Overview" style="display: block; margin: 15px auto; max-width: 50%; height: auto;">
    <ol>
        <li>
            <strong>Cooperative Behavior Analysis:</strong>
            Conducted systematic experiments to observe cooperation and betrayal decisions across multiple LLMs, providing insights into their decision-making patterns in a game-theoretic context.
        </li>
        <li>
            <strong>Behavioral Prompting Mechanism:</strong>
            Developed a high-level transformer-based mechanism that increased the average cooperation rate by 30% in RPD scenarios.
        </li>
        <li>
            <strong>Experiment Replication:</strong>
            Successfully replicated a foundational 1981 Science paper’s experimental setup, overcoming significant challenges in deciphering and reconstructing its ambiguous textual descriptions. 
            This effort resulted in a more robust understanding of its conclusions and is being prepared for submission to an economics journal.
        </li>
    </ol>
    
    <h2>Challenges and Reflections</h2>
    <p>
        The project encountered significant obstacles, particularly in replicating the results of the seminal 1981 study, which lacked source code and detailed documentation. 
        These difficulties underscored the importance of transparent research practices and led to the development of a custom experimental environment. 
        Additionally, this work cultivated critical skills in leveraging LLMs for collaborative decision-making and highlighted the value of questioning and verifying influential prior studies.
    </p>
    
    <h2>Personal Growth</h2>
    <p>
        This research provided extensive hands-on experience with LLM API integrations and prompt engineering, deepening my understanding of multi-agent systems and cooperative strategies. 
        It also fostered critical thinking skills, as I scrutinized and reconstructed historically impactful research, contributing to the broader academic discourse on the reproducibility of seminal studies.
    </p>
</body>
</html>
