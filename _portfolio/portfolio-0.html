---
title: "Large Language Models in Iterated Prisoner's Dilemma: Impact of High-level behavior prompter on Cooperation"
excerpt: "This project, conducted under the supervision of Professor Zhigang Cao, explores the intersection of LLMs and game theory, it formed my undergraduate thesis. I analyzed the behavior of LLMs in the Iterated Prisoner's Dilemma and developed a high-level cueing algorithm to increase their cooperation rates in this game theory scenario."
collection: portfolio
---

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Behavior Research of LLMs in Iterated Prisoner’s Dilemma</title>
</head>
<body>
    <h2>Background</h2>
    <p>
        This project explores the intersection of <strong>AI and game theory</strong>.
    </p>

    <p>
    Iterated Prisoner’s Dilemma (IPD) is a classical model in game theory and is widely applied in fields such as evolutionary biology, economics, and computer science. In IPD, participants choose between cooperation and defection in each round of the game, with their decisions directly affecting their immediate and long-term rewards. The core of IPD lies in its ability to reveal the dynamic relationship between cooperation and betrayal, especially in environments with repeated interactions.
    The payoff structure of IPD, as shown below, reflects the outcomes of different strategies:
    </p>
    
    <img src="/images/prisoner_dilemma.png" alt="Project Overview" style="display: block; margin: 15px auto; max-width: 70%; height: auto;"
    <ul>
        <li><strong>Mutual Cooperation:</strong> Both players receive a payoff of 3 points.</li>
        <li><strong>Unilateral Defection:</strong> The defector earns 5 points, while the cooperator earns 0 points.</li>
        <li><strong>Mutual Defection:</strong> Both players receive a payoff of 1 point.</li>
    </ul>

    <img src="/images/bs.png" alt="Project Overview" style="display: block; margin: 15px auto; max-width: 70%; height: auto;">
    
    <p>
        Motivated by the growing prominence of large language models (LLMs) and their potential applications, the primary objective of this project is:
    </p>

    <ol>
        <li><strong>LLM Behavior Analysis:</strong> To examine the intrinsic behavioral tendencies of LLMs in game-theoretic scenarios, specifically cooperation and betrayal in IPD</li>
        <li><strong>Enhancing Cooperation:</strong> It aims to enhance the cooperation rate among agents in this game through a high-level behavioral prompting mechanism, trained using a Transformer model. By fostering higher levels of collaboration, this approach ultimately increases the overall societal payoff and offers a novel perspective on multi-agent cooperation.</li>
    </ol>
    
    <p>
        This research received a nomination for Outstanding Undergraduate Graduation Project.
    </p>
    
    <h2>Methodology</h2>
    <img src="/images/prisoner_dilemma_mathod.png" alt="Project Overview" style="display: block; margin: 15px auto; max-width: 80%; height: auto;"
    <p>The project involved designing a custom experimental environment to simulate IPD interactions among multiple LLMs, such as ChatGPT and Tongyi Qianwen. The primary steps included:</p>
    <ul>
        <li><strong>Game Environment Setup:</strong> Game Environment Setup: Developing a robust simulation framework for repeated RPD experiments, integrating API-based interactions with various LLMs, and leveraging chain-of-thought techniques to design meticulously crafted prompts. These prompts were used to guide the decision-making processes of LLMs during gameplay, 
            enabling a more nuanced exploration of their behavior in the iterative dilemma scenarios.</li>
        <li><strong>Behavioral Prompting Mechanism:</strong> Drawing inspiration from the hierarchy decision transformer model, a high-level transformer was developed to process historical game data and generate strategic prompts for LLMs. This mechanism aimed to enhance cooperative outcomes during their interactions.</li>
        <li><strong>Empirical Evaluation:</strong> Analyzing LLM behavior with and without the high-level prompting mechanism to quantify its impact on cooperative behavior.</li>
    </ul>
    
    <h2>Key Achievements</h2>
    <img src="/images/prisoner_dilemma_result.png" alt="Project Overview" style="display: block; margin: 15px auto; max-width: 60%; height: auto;">
    <ol>
        <li>
            <strong>Cooperative Behavior Analysis:</strong>
            Conducted systematic experiments to observe cooperation and betrayal decisions across multiple LLMs, providing insights into their decision-making patterns in a game-theoretic context.
        </li>
        <li>
            <strong>Behavioral Prompting Mechanism:</strong>
            Developed a high-level transformer-based mechanism that increased the average cooperation rate by 30% in RPD scenarios.
        </li>
    </ol>
    
    <h2>Challenges and Reflections</h2>
    <p>
        The project faced two primary challenges:
    </p>
    <ol>
        <li>Integrating cutting-edge LLMs into the classical  and well-established framework of game theory, specifically the IPD, required interdisciplinary research capabilities and groundwork in both fields. This demanded a deep understanding of both the technical intricacies of LLMs and the theoretical underpinnings of game theory. </li>
        <li>Designing effective prompts to enable these advanced models to engage in meaningful and valid gameplay posed a substantial technical challenge. The process revealed the critical role of prompt engineering, showcasing it as a powerful and transformative tool for shaping LLM behavior in structured environments. These experiences emphasized the importance and potential of prompt design in harnessing the full capabilities of LLMs for complex tasks.</li>
    </ol>
    
</body>
</html>
