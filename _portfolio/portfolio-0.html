---
title: "Large Language Models in Iterated Prisoner's Dilemma: Impact of High-level behavior prompter on Cooperation"
excerpt: "This project, conducted under the supervision of Professor Zhigang Cao, explores the intersection of LLMs and game theory, it formed my undergraduate thesis. I analyzed the behavior of LLMs in the Iterated Prisoner's Dilemma and developed a high-level cueing algorithm to increase their cooperation rates in this game theory scenario.
 <br/><img src="/images/bs.png">"
collection: portfolio
---

Background
This project, conducted under the supervision of Professor Zhigang Cao at the School of Economics and Management, Beijing Jiaotong University, explores the intersection of artificial intelligence and game theory. Motivated by the growing prominence of large language models (LLMs) and their potential applications, the study investigates the behavior of LLMs within the framework of the classic Repeated Prisoner’s Dilemma (RPD). This research, which spanned from April 2023 to June 2024, received a nomination for Outstanding Undergraduate Graduation Project.

Objectives
LLM Behavior Analysis: To examine the intrinsic behavioral tendencies of LLMs in game-theoretic scenarios, specifically cooperation and betrayal in RPD.
Enhancing Cooperation: To design a high-level behavioral prompting mechanism that leverages historical game data to guide LLMs towards higher cooperative rates in iterative dilemmas.
Methodology
The project involved designing a custom experimental environment to simulate repeated Prisoner’s Dilemma interactions among multiple LLMs, such as ChatGPT and Tongyi Qianwen. The primary steps included:

Game Environment Setup: Developing a simulation framework for repeated RPD experiments and integrating API-based interactions with various LLMs.
Behavioral Prompting Mechanism: Drawing inspiration from the hierarchy decision transformer model, a high-level transformer was developed to process historical game data and generate strategic prompts for LLMs. This mechanism aimed to enhance cooperative outcomes during their interactions.
Empirical Evaluation: Analyzing LLM behavior with and without the high-level prompting mechanism to quantify its impact on cooperative behavior.
Key Achievements
Cooperative Behavior Analysis:
Conducted systematic experiments to observe cooperation and betrayal decisions across multiple LLMs, providing insights into their decision-making patterns in a game-theoretic context.
Behavioral Prompting Mechanism:
Developed a high-level transformer-based mechanism that increased the average cooperation rate by 30% in RPD scenarios.
Experiment Replication:
Successfully replicated a foundational 1981 Science paper’s experimental setup, overcoming significant challenges in deciphering and reconstructing its ambiguous textual descriptions. This effort resulted in a more robust understanding of its conclusions and is being prepared for submission to an economics journal.
Challenges and Reflections
The project encountered significant obstacles, particularly in replicating the results of the seminal 1981 study, which lacked source code and detailed documentation. These difficulties underscored the importance of transparent research practices and led to the development of a custom experimental environment. Additionally, this work cultivated critical skills in leveraging LLMs for collaborative decision-making and highlighted the value of questioning and verifying influential prior studies.

Personal Growth
This research provided extensive hands-on experience with LLM API integrations and prompt engineering, deepening my understanding of multi-agent systems and cooperative strategies. It also fostered critical thinking skills, as I scrutinized and reconstructed historically impactful research, contributing to the broader academic discourse on the reproducibility of seminal studies.
